---
title: "Constrained analyses"
output: learnr::tutorial
runtime: shiny_prerendered
---

```{r setup, include=FALSE}
library(learnr)
library(mosaic)
library(vegan)
library(ggvegan)
data(dune)
data(dune.env)
data(varespec)
data(varechem)
knitr::opts_chunk$set(echo = FALSE)
```


## Multiple responses plus explanatory variables
### Introduction
Unconstrained ordination methods such as PCA, CA and NMDS allow you to summarise
the relationships between your samples (sites, isolates, quadrats etc.) and your
attributes (species, gene sequences etc.). They provide a useful method to 
simplify your data so that it can be viewed in a 2-dimensional ordination plot.
The scores from these plots, especially the first axis, can sometimes be related
to potential explanatory variables to aid interpretation, as you showed with
soil moisture and the dune vegetation analysis.

If you have explanatory variables, you might be tempted to extract an ordination
axis, and after visualising any patterns with a potential explanatory variable,
undertake a linear model, with your chosen **ordination axis** as your response.
For example, recall that you undertook a PCA of the sand dune vegetation data,
and showed a clear pattern with Moisture:

```{r dune_pca, echo=TRUE}
# PCA of dune data
dune_pca <- rda(dune)

# Plot of PC1 vs PC2
autoplot(dune_pca, layers="sites", legend.position="none", geom="text",
         title = "PCA of dune vegetation; site codes.")

# Extract PC1 and relate to soil moisture category
dune_pc1 <- scores(dune_pca, display="sites", choices = 1)
gf_boxplot(dune_pc1 ~ Moisture, data=dune.env)
```

Now let's do a linear model to formally test the relationship between soil
moisture and dune vegetation composition as described by PC1. We'll display
the ANOVA table, and check the first two model diagnostic plots (residuals and
QQ plots):

```{r dune_pca_lm, echo=TRUE}
dune_lm <- lm(dune_pc1 ~ Moisture, data=dune.env)
anova(dune_lm)
mplot(dune_lm, which=1:2)

```

The relationship with moisture class is highly significant, with F=14.94426 and
p=6.691419e-05 which is p=0.00006691419 (**remember** you would report these as
"F=14.94, p<0.001"). There are no obvious problems with the residuals vs fitted
plot, with an even scatter around the zero line. The QQ plot looks good, with
most points along the expected diagonal line.

When techniques to handle lots of response variables were first developed, this
was the most common method of analysis. It is sometimes referred to as **indirect gradient analysis**
and was widely used until the 1990's.

## Problems with indirect gradient analysis
The linear model presented on the previous page showed no obvious problems, so
the disadvantages of indirect gradient analysis may not be immediately obvious.
However, one assumption of linear models (and GLMs), is that all your response
data points are independent of each other:

* The composition of plants in your first quadrat should not affect those in your second. 
* The gene sequence from your third isolate should not change those in your fifth
* The bacterial OTU samples from Chile should be independent of the OTUs obtained from France
* The types of insects found in your pitfall trap sample from Northumberland should
not influence those found in your pitfall trap from Cornwall

This seems fairly obvious, and in practical terms, when you collect the data from
field surveys or laboratory experiments, the various samples are independent. The
problem arises from what happens when you undertake an unconstrained ordination.

### Non-independence of ordination scores
Let's repeat our PCA of the sand dune vegetation, but omit one of the samples
at random (sample 6):

```{r compare_pca}
# Multiple plot function from http://www.cookbook-r.com/Graphs/Multiple_graphs_on_one_page_(ggplot2)/ 
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  library(grid)

  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)

  numPlots = length(plots)

  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                    ncol = cols, nrow = ceiling(numPlots/cols))
  }

 if (numPlots==1) {
    print(plots[[1]])

  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))

    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))

      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

dune_pca <- rda(dune)
dune_pca_no6 <- rda(dune[-6,])
dune_plt1 <- autoplot(dune_pca, display="sites", geom="text", legend.position = "none",
                      title="PCA with full dataset")
dune_plt2 <- autoplot(dune_pca_no6, display="sites", geom="text", legend.position = "none",
                      title="PCA with one sample omitted")
multiplot(dune_plt1, dune_plt2, cols=2)
```

You can see that the whole ordination has 'flipped' on its vertical axis. Depending
on your data, sometimes both PC1 and PC2 will flip or rotate. The relative positions
of the samples are still roughly the same, in the samples similar in their species
composition (e.g. 17, 18 and 19) are still relatively close to each other, but they
have nevertheless moved.

**Key point**
Whilst your original quadrats, isolates, samples or sites may have been independent
from each other, once they are converted to PCA axis scores, the actual scores are
**not** independent. Fortunately, an alternative method to resolve this problem,
known as **constrained ordination** was developed in 1989, and has since become
a standard technique for biologists.

## Constrained ordination
In a constrained ordination the explanatory variables (categorical and/or
continuous) are incorporated into the ordination itself. The sample scores are
constrained to be linear combinations of the various explanatory variables,
whilst simultaneously accounting for the composition of the attributes. So the
overall format is:

$$\text{Table of response variables} = \text{Explanatory variables} + \epsilon$$

Note that the technique does not work effectively if you only have one or two
explanatory variables, as it may constrain all your samples or attributes too
much along one axis. The display of constrained analysis is in the form of 
modified ordination plots, which can be very informative once you have learnt
how to interpret them. You can also undertake formal statistical tests using
analyses analogous to ANOVA. The technique will also cope with complex experimental
designs, such as blocked designs, or time-series. You can also create interaction
terms if needed.

Constrained analysis exists in two main forms, linear and unimodal. The linear
form is Redundancy Analysis (RDA) and unimodal is Canonical Correspondence Analysis
(CCA). These are run using the `rda()` and `cca()` functions respectively, which
you have already used for PCA and CA. However, if you give the functions explanatory
variables they automatically change to RDA and CCA.

## Example constrained ordination
Let's look at our reindeer-grazed Pine forests that we discussed earlier. This
comes with a large set of potential explanatory variables, about the soil chemistry,
pH etc., stored in the table `varechem` but we will just use a few for simplicity:

```{r varechem, echo=TRUE}
head(varechem)
summary(varechem)
```

Now the actual analysis, using CCA, as you will recall that we had to use CA rather
than PCA for the unconstrained analysis of these data. We will just use potassium (`K`),
phosphorus (`P`), Aluminium (`Al`), soil pH (`pH`), and the amount of bare ground 
(`Baresoil`) as explanatories:

```{r varespec_cca, exercise=TRUE}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
summary(varespec_cca)[["cont"]][["importance"]]
```

When you run the `summary()` function on its own you will see a very large amount
of output; this is fine in RStudio, but I have simplified it to just the `importance`
measures for this website. Again, it provides information of the amount of variation
explained by CCA1 (17.7%) and CCA2 (9.3%) so the first two axes explain roughly
27% of the variation.

What can be more useful are the plots. The default is a **triplot** which shows
the samples (sites), attributes (species), and explanatory variables (soil chemistry)
all in one plot. Note:

* If the explanatory variables are **continuous** (as here) they are shown in the
plot as arrows.
* If the explanatory variables are **categorical** they are shown as points, with
a different point for each of your category levels
* You can of course have a mixture of continuous and categorical variables

```{r varespec_triplot-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r varespec_triplot, exercise=TRUE}
autoplot(varespec_cca)
```
```{r varespec_triplot-solution}
autoplot(varespec_cca, geom="text", legend.position = "none")
```

Unless there are relatively few samples or attributes, the plot will not label
the points unless you add the `geom="text"` option. Modify the script above to
see the difference: with everything plotted this is probably too difficult to
interpret. Nevertheless, even with this rather cluttered plot, you can immediately
make inferences about the explanatory variables:

* Important explanatory variables have **longer arrows**, less important variables
have **short arrows**
* Two explanatory variables that are **positively correlated** in their effects
will point in the **same** direction
* Two explanatory variables that are **negatively correlated** to each other will
point in **opposite** directions
* Two explanatory variables that are **correlated** with each other will have 
arrows at roughly 90 degrees to each other.

Looking at the explanatory variables above, which statement is correct?

```{r interpret_explanatories}
question("The following are negatively correlated with each other",
         answer("K and P"),
         answer("K and pH"),
         answer("pH and Al"),
         answer("Al and K"),
         answer("P and Al"),
         answer("Al and pH"),
         answer("pH and Baresoil", correct=TRUE),
         random_answer_order = TRUE,
         allow_retry = TRUE)
```

To get a clearer picture of the samples and species, it is generally easier to
plot them separately, along with the explanatory variables. Notice that in the
commands below we ask `autoplot()` to `display=c("sites", "bp")` or `display=c("species", "bp")`
where `bp` represents the "biplot" arrow points. If you have **categorical**
explanatory variables replace these with `display=c("sites", "cn")` where the
`cn` represents "centroids" for each level of your category. If you have a
mixture of **both continuous and categorical** explanatories, use the format
`display=c("sites", "bp", "cn")`,

```{r cca_separate_plots-setup}
varespec_cca <- cca(varespec ~ K + P + Al + pH + Baresoil, data=varechem)
```
```{r cca_separate_plots, exercise=TRUE}
autoplot(varespec_cca, geom="text", display=c("sites", "bp"), legend.position = "none")
autoplot(varespec_cca, geom="text", display=c("species", "bp"), legend.position = "none")
```

These plots tell you key things about the samples and attributes in relation to
the explanatory variables. For example:

* There is a relatively large amount of bare soil at samples 22, 16, 14, and 
relatively little bare soil at sites 2, 3, 4, 9, 10, 12
* Samples 24, 25, 27, 28 are relatively high in P and K, whilst samples 5, 6, 7
13 and 18 have low P and K
* Al and pH are probably highest in samples 3 and 4
* Species associated with more bare soil include Betupube, Barbhatc, Ptilcili
* Species associated with low K and P include Callvulg, Icmaeric and Vacculig

### Bare soil is not soil chemistry!
The longest arrow (and hence most important explanatory variable) is bare soil.
However, this is not of course soil chemistry, and so you might be interested in
looking at what is going on **after** taking into account the effects of bare soil.
This is easy to do with a **partial constrained analysis**. Simply add the term
`Condidition(Baresoil)` to your explanatory variables to remove its effect.

```{r partial_cca, exercise=TRUE}
varespec_cca2 <- cca(varespec ~ K + P + Al + pH + Condition(Baresoil), data=varechem)
autoplot(varespec_cca2, geom="text", display=c("sites", "bp"), legend.position = "none")
autoplot(varespec_cca2, geom="text", display=c("species", "bp"), legend.position = "none")
```

You can see that once we have "conditioned" for the effects of bare soil, the
relationships between the explanatory variables are much clearer.

**Note**. As there are a large number of attributes in these plots, they are 
still difficult to read. The ubiquitous species in the centre of the plot are of
little interest, and do not need labelling. At present there is not a simple way
of switching off their labelling within ggvegan, but if you look 
<a href="https://blogs.ncl.ac.uk/mep/2018/04/08/reproducible-publication-quality-multivariate-plots-in-r/" target="_blank">this website</a> it shows you one method of creating clearer plots.

